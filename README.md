# HustleBuddy üöÄ

## Overview

HustleBuddy is an intelligent AI model evaluation platform that compares and analyzes the content generated by three different AI models based on a given prompt. The system provides comprehensive analysis of Model 1's performance against Models 2 and 3, focusing on both critical and non-critical evaluation rubrics to deliver actionable insights for improving model performance.

## üåü Key Features

- **AI Model Response Comparison**: Analyze and compare outputs from three different AI models
- **Comprehensive Evaluation Framework**: Uses 10+ evaluation rubrics (6 critical + 4 non-critical)
- **Knowledge-Enhanced Analysis**: Leverages a specialized knowledge base with Ballerina programming language documentation
- **RESTful API**: FastAPI backend with comprehensive endpoints
- **Modern Web Interface**: React-based frontend for easy interaction
- **Vector Database Integration**: Hybrid search capabilities using PostgreSQL with pgvector

## üèóÔ∏è Architecture

### Backend (`/backend`)

The backend is built with FastAPI and features:

- **AI Agent System**: Powered by Agno framework with OpenAI GPT-4o-mini
- **Knowledge Base**: PDF-based RAG (Retrieval-Augmented Generation) system
- **Vector Database**: PostgreSQL with pgvector for semantic search
- **API Endpoints**: RESTful services for model evaluation and knowledge management

#### Core Components:

1. **Agent (`agent/agent.py`)**: Core AI agent implementation using Agno framework
2. **Knowledge RAG (`agent/knowledge_rag.py`)**: PDF knowledge base with vector search
3. **Agent Configuration (`agent-config.json`)**: Detailed agent behavior and evaluation criteria
4. **Main API (`main.py`)**: FastAPI application with CORS support and comprehensive error handling

### Frontend (`/frontend`)

React-based web application providing:

- **Model Comparison Interface**: Input forms for prompt and three model responses
- **Real-time Evaluation**: Submit requests to backend for analysis
- **Markdown Support**: Rich formatting for analysis results display
- **Responsive Design**: Modern UI with comprehensive result visualization

## ü§ñ AI Agent Capabilities

### HustleBuddy Agent

The core AI agent is configured with specific expertise in model evaluation:

**Name**: HustleBuddy  
**Model**: OpenAI GPT-4o-mini  
**Specialization**: AI model response analysis and comparison

#### Evaluation Framework

The agent evaluates Model 1 against Models 2 and 3 using:

##### Critical Rubrics (6):

1. **Relevance to Prompt** - How well content addresses the given prompt
2. **Clarity of Expression** - Assessment of language clarity and readability
3. **Depth of Analysis** - Thoroughness of information provided
4. **Accuracy of Information** - Factual correctness verification
5. **Logical Structure** - Organization and flow of arguments
6. **Engagement Level** - Content engagement quality

##### Non-Critical Rubrics (4+):

1. **Use of Examples** - Support for claims with examples
2. **Tone and Style** - Appropriateness for target audience
3. **Conciseness** - Information presentation efficiency
4. **Originality** - Content uniqueness assessment

#### Analysis Focus

- **Advantages Identification**: Areas where Model 1 excels
- **Disadvantage Analysis**: >60% focus on Model 1's shortcomings
- **Evidence-Based Assessment**: Specific examples from content
- **Actionable Recommendations**: Improvement suggestions with priority levels

### Knowledge Base Integration

The agent is enhanced with a specialized knowledge base containing:

- **Ballerina Programming Language Documentation**:
  - Best practices and coding standards
  - Common error patterns and solutions
  - Evaluation criteria and examples
  - Task specifications and examples

The knowledge base supports:

- **Hybrid Search**: Combines semantic and keyword search
- **PDF Processing**: Automated extraction and vectorization
- **Context-Aware Retrieval**: Relevant information retrieval for evaluations

## üõ†Ô∏è Technology Stack

### Backend

- **Framework**: FastAPI
- **AI Framework**: Agno
- **Language Model**: OpenAI GPT-4o-mini
- **Vector Database**: PostgreSQL with pgvector
- **Search Engine**: LanceDB with Tantivy
- **PDF Processing**: PyPDF
- **Embeddings**: sentence-transformers

### Frontend

- **Framework**: React 19.1.0
- **Styling**: CSS with modern responsive design
- **Markdown Rendering**: react-markdown
- **Testing**: React Testing Library

### Infrastructure

- **Containerization**: Docker Compose
- **Database**: PostgreSQL with vector extensions
- **Environment Management**: python-dotenv

## üöÄ Quick Start

### Prerequisites

- Python 3.8+
- Node.js 16+
- PostgreSQL with pgvector extension
- OpenAI API key

### Backend Setup

1. **Clone and navigate to backend**:

   ```bash
   cd backend
   ```

2. **Install dependencies**:

   ```bash
   pip install -r requirements.txt
   ```

3. **Set environment variables**:

   ```bash
   export OPENAI_API_KEY="your-openai-api-key"
   ```

4. **Start PostgreSQL** (using Docker):

   ```bash
   docker-compose up -d
   ```

5. **Run the API server**:
   ```bash
   python main.py
   ```

### Frontend Setup

1. **Navigate to frontend**:

   ```bash
   cd frontend
   ```

2. **Install dependencies**:

   ```bash
   npm install
   ```

3. **Start development server**:
   ```bash
   npm start
   ```

## üìñ API Documentation

### Core Endpoints

- **POST /evaluate**: Compare AI model responses
- **GET /knowledge-status**: Check knowledge base status
- **POST /load-knowledge**: Load/reload knowledge base
- **GET /health**: Health check
- **GET /docs**: Interactive API documentation

### Example Request

```json
{
  "prompt": "Explain how distributed training works",
  "model1": "Model 1 response...",
  "model2": "Model 2 response...",
  "model3": "Model 3 response...",
  "use_knowledge": true
}
```

### Example Response

```json
{
  "status": "success",
  "analysis": "üìä **Model 1 Comparative Analysis Report**...",
  "metadata": {
    "prompt_length": 45,
    "model1_length": 250,
    "model2_length": 300,
    "model3_length": 280,
    "knowledge_used": true,
    "session_id": "session-123"
  }
}
```

## üîß Configuration

### Agent Configuration

The agent behavior is controlled through `backend/agent-config.json`:

- **Evaluation Instructions**: Detailed rubric definitions
- **Output Format**: Structured analysis template
- **Agent Settings**: History tracking, markdown support, tool visibility

### Knowledge Base Configuration

Located in `backend/agent/knowledge_rag.py`:

- **Database URL**: PostgreSQL connection string
- **Document Path**: PDF files location
- **Search Type**: Hybrid semantic + keyword search

## ü§ù Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## üìÑ License

This project is licensed under the MIT License - see the LICENSE file for details.

## üéØ Use Cases

- **AI Model Development**: Compare different model versions
- **Quality Assurance**: Evaluate model outputs against standards
- **Research**: Analyze model behavior patterns
- **Education**: Learn about AI model evaluation techniques
- **Ballerina Development**: Leverage specialized knowledge base for code evaluation

## üìû Support

For questions or support, please open an issue in the GitHub repository or contact the development team.

---

**HustleBuddy** - Empowering better AI through intelligent evaluation üöÄ
